{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd41e9a8",
   "metadata": {},
   "source": [
    "<font size=6>Downloading required libraries</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be7a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q numpy\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n",
    "!pip3 install torch torchsummary\n",
    "!pip3 install torch tensorboard\n",
    "!pip3 install -q pretty_midi\n",
    "!pip3 install -q gensim\n",
    "!pip3 install -q nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4068e6c",
   "metadata": {},
   "source": [
    "<font size=6>Imports</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a414349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import zipfile\n",
    "import requests\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "import gdown\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "from glob import glob\n",
    "from typing import Optional\n",
    "import csv\n",
    "import string\n",
    "from pretty_midi import PrettyMIDI, Note\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import gensim.downloader\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "nltk.download('stopwords')\n",
    "import pickle\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import deque\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "print(\"Using torch\", torch.__version__)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9359ed8",
   "metadata": {},
   "source": [
    "<font size=6>Constants</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "60457569",
   "metadata": {},
   "outputs": [],
   "source": [
    "LYRIC_TRAIN_SET_CSV_PATH: str = os.path.join(os.getcwd(), 'data', 'lyrics_train_set.csv')\n",
    "LYRIC_TEST_SET_CSV_PATH: str = os.path.join(os.getcwd(), 'data', 'lyrics_test_set.csv')\n",
    "MIDI_FILE_PATH: str = os.path.join(os.getcwd(), 'data', 'midi_files')\n",
    "PICKLING_PATH: str = os.path.join(os.getcwd(), 'loaded_midi_files.pkl') # Path to save/load pickled MIDI files, for faster loading.\n",
    "EPSILON: float = 1e-9\n",
    "SEQUENCE_LENGTH: int = 10  # Number of words in the input sequence\n",
    "BATCH_SIZE: int = 128\n",
    "LSTM_LAYERS: int = 2\n",
    "DROPOUT: float = 0.3\n",
    "RANDOM_LOADER_SEED: int = 42\n",
    "VALIDATION_SPLIT: float = 0.1\n",
    "LEARNING_RATE: float = 0.001\n",
    "MAX_EPOCHS: int = 50\n",
    "NUMBER_OF_EXTRACT_MIDI_FEATURES: int = 33\n",
    "WORD_EMBEDDING_SIZE: int = 300\n",
    "PATIANCE_FACTOR: float = 0.001\n",
    "PATIANCE_EPOCHS: int = 10\n",
    "UNK_ID: int = 0\n",
    "MIN_LINE_LENGTH: int = 5\n",
    "MAX_LINE_LENGTH: int = SEQUENCE_LENGTH\n",
    "EOL_STRING: str = 'eol'\n",
    "UNK_STRING: str = 'unk'\n",
    "EOS_STRING: str = '<eos>'\n",
    "TOP_K_WORDS_TO_PREDICT: int = 20\n",
    "MAX_SONG_LENGTH_WORDS: int = 80\n",
    "HIDDEN_LAYER_DIM: int = 256\n",
    "DEFAULT_MIDI_SCALE: float = 1.0\n",
    "SEED = 42\n",
    "VERBOSE: str = True\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1947ce",
   "metadata": {},
   "source": [
    "<font size=6>Midi Feature extraction</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f083e542",
   "metadata": {},
   "source": [
    "Auxlliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8216678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_time_signature(changes: tuple[int, int]) -> tuple[int, int]:\n",
    "    if not changes: return (4, 4)\n",
    "    pairs: list[tuple[int, int]] = [(ts.numerator, ts.denominator) for ts in changes]\n",
    "    return Counter(pairs).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2526597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration_weighted_pitch_stats(notes: list[Note]) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute pitch statistics weighted by each note's duration.\n",
    "    Returns a dict with:\n",
    "      mean (duration-weighted),\n",
    "      std  (duration-weighted),\n",
    "      p10 / p50 / p90 (duration-weighted percentiles),\n",
    "      ambitus = p90 - p10 (robust range).\n",
    "    If `notes` is empty, returns safe defaults.\n",
    "    \"\"\"\n",
    "    # Empty guard: nothing to measure â†’ return neutral stats.\n",
    "    if not notes:\n",
    "        return dict(mean=0.0, std=0.0, p10=-1, p50=-1, p90=-1, ambitus=0.0)\n",
    "\n",
    "    # Vectorize pitches as float for math (MIDI 0..127, but floats simplify ops).\n",
    "    pitches: np.ndarray[np.float32] = np.fromiter((n.pitch for n in notes), dtype=np.float32)\n",
    "\n",
    "    # Each note's weight = its duration in seconds; clamp tiny/negative to epsilon.\n",
    "    weights: np.ndarray[np.float32] = np.fromiter((max(EPSILON, n.end - n.start) for n in notes), dtype=np.float32)\n",
    "    total_weights: float = weights.sum()\n",
    "    duration_weight_mean: float = float((weights * pitches).sum() / total_weights)\n",
    "    duration_weighted_variance: float = float((weights * (pitches - duration_weight_mean) ** 2).sum() / total_weights)\n",
    "    weighted_std: float = duration_weighted_variance ** 0.5\n",
    "\n",
    "    # ---------- Duration-weighted percentiles ----------\n",
    "    order: np.ndarray[np.int32] = np.argsort(pitches)\n",
    "    ordered_pitches, ordered_weights = pitches[order], weights[order]\n",
    "    cumulative_weight_sum: np.ndarray[np.float32] = np.cumsum(ordered_weights)\n",
    "\n",
    "    # Weighted quantile: find the first index where cumulative weight crosses q%.\n",
    "    def weighted_quantile(quantile: float) -> float:\n",
    "        # Target cumulative weight at quantile q (0..100).\n",
    "        target: float = (quantile / 100.0) * cumulative_weight_sum[-1]\n",
    "        # Index where cumulative_weight_sum >= target; take leftmost to be consistent.\n",
    "        idx: int = np.searchsorted(cumulative_weight_sum, target, side=\"left\")\n",
    "        return float(ordered_pitches[min(idx, len(ordered_pitches) - 1)])\n",
    "\n",
    "    # 10th / 50th (median) / 90th percentiles, duration-weighted.\n",
    "    percentile_10, percentile_50, percentile_90 = weighted_quantile(10), weighted_quantile(50), weighted_quantile(90)\n",
    "\n",
    "    # Ambitus = robust spread (p90 - p10), less sensitive than raw max - min.\n",
    "    return dict(mean=duration_weight_mean, \n",
    "                std=weighted_std,\n",
    "                p10=percentile_10, \n",
    "                p50=percentile_50, \n",
    "                p90=percentile_90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66999304",
   "metadata": {},
   "source": [
    "Extracting high level features relating to the entire song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85395762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_midi_features(midi: PrettyMIDI) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return song-level features (vector+names).\n",
    "    \"\"\" \n",
    "    duration_sec: float = midi.get_end_time()                                       # total length\n",
    "    if duration_sec <= 0: raise ValueError(\"Empty/zero-length MIDI.\")        # guard\n",
    "\n",
    "    tempo_times, tempo_bpms = midi.get_tempo_changes()                               # tempo changes\n",
    "    if len(tempo_bpms) == 0:                                                     # no changes\n",
    "        tempo_times = np.array([0.0], dtype=np.float32)                          # start time\n",
    "        tempo_bpms = np.array([midi.estimate_tempo()], dtype=np.float32)         # single bpm\n",
    "    segment_ends: np.ndarray[np.float32] = np.r_[tempo_times[1:], duration_sec]                              # segment ends\n",
    "    segment_durs: np.ndarray[np.float32] = np.maximum(1e-6, segment_ends - tempo_times[:len(segment_ends)])          # segment durations\n",
    "    tempo_mean: float = float(np.dot(tempo_bpms[:len(segment_durs)], segment_durs) / np.sum(segment_durs)) # duration-weighted mean\n",
    "    tempo_std: float = float(np.std(np.repeat(\n",
    "        tempo_bpms[:len(segment_durs)],                                              # repeat bpm by\n",
    "        np.maximum(1, (segment_durs/np.sum(segment_durs)*1000).astype(int))          # rough weights\n",
    "    )))                                                                       # dispersion proxy\n",
    "    tempo_change_count: int = int(len(tempo_bpms))                                     # number of states\n",
    "\n",
    "    time_signature_numerator, time_signature_denominator = most_common_time_signature(midi.time_signature_changes)  # mode time sig\n",
    "    instrument_count: int = sum(1 for inst in midi.instruments                     # non-drum count\n",
    "                          if not inst.is_drum and inst.notes)\n",
    "\n",
    "    instruments: list = [inst for inst in midi.instruments if not inst.is_drum and inst.notes]\n",
    "    instruments_velocities: list[float] = []\n",
    "    instrument_notes: list[Note] = []\n",
    "    for instrument in instruments:                                 # melody track\n",
    "        mel_velocity = [note.velocity for note in instrument.notes]     # melody velocities\n",
    "        instruments_velocities.extend(mel_velocity)\n",
    "        instrument_notes.extend(instrument.notes)\n",
    "\n",
    "    instrument_velocities_min: float = min(instruments_velocities)      # min pitch\n",
    "    instrument_velocities_max: float = max(instruments_velocities)      # max pitch\n",
    "    instrument_velocities_mean: float = np.mean(instruments_velocities)    # mean pitch\n",
    "    instrument_velocities_std: float = np.std(instruments_velocities)     # std pitch\n",
    "\n",
    "    duration_weight_pitch_stats_dict: dict = get_duration_weighted_pitch_stats(instrument_notes)\n",
    "    instrument_pitch_10_percentile: float = duration_weight_pitch_stats_dict['p10']\n",
    "    instrument_pitch_50_percentile: float = duration_weight_pitch_stats_dict['p50']\n",
    "    instrument_pitch_90_percentile: float = duration_weight_pitch_stats_dict['p90']\n",
    "    instrument_pitch_mean: float = duration_weight_pitch_stats_dict['mean']\n",
    "    instrument_pitch_std: float = duration_weight_pitch_stats_dict['std']\n",
    "    instrument_pitch_range_by_percentiles: float = instrument_pitch_90_percentile - instrument_pitch_10_percentile\n",
    "\n",
    "    note_durations: list[float] = [note.end - note.start for note in instrument_notes]\n",
    "    note_durations_mean: float = np.mean(note_durations) if note_durations else 0.0\n",
    "    note_durations_std: float = np.std(note_durations) if note_durations else 0.0\n",
    "    note_durations_range: float = max(note_durations) - min(note_durations) if note_durations else 0.0\n",
    "\n",
    "    note_density: float = float(len(instrument.notes) / max(EPSILON, duration_sec))           # notes/sec\n",
    "\n",
    "    chroma_global = midi.get_pitch_class_histogram(use_duration=True)        # 12-bin chroma\n",
    "    chroma_global = chroma_global / (np.sum(chroma_global) + EPSILON)           # normalize\n",
    "    names = [                                                                # feature names\n",
    "        \"duration_sec\",\n",
    "        \"tempo_mean_bpm\", \n",
    "        \"tempo_std_bpm\", \n",
    "        \"tempo_change_count\",\n",
    "        \"time_sig_num\", \n",
    "        \"time_sig_den\",\n",
    "        \"instrument_count\",\n",
    "        \"instrument_velocities_min\", \n",
    "        \"instrument_velocities_max\", \n",
    "        \"instrument_velocities_mean\", \n",
    "        \"instrument_velocities_std\", \n",
    "        \"instrument_pitch_10_percentile\",\n",
    "        \"instrument_pitch_50_percentile\",\n",
    "        \"instrument_pitch_90_percentile\",\n",
    "        \"instrument_pitch_mean\",\n",
    "        \"instrument_pitch_std\",\n",
    "        \"instrument_pitch_range_by_percentiles\",\n",
    "        \"note_durations_mean\",\n",
    "        \"note_durations_std\",\n",
    "        \"note_durations_range\",\n",
    "        \"melody_note_density_per_sec\",\n",
    "    ] + [f\"chroma_{i}\" for i in range(12)]                                   # chroma names\n",
    "    vec = np.array([                                                         # feature vector\n",
    "        duration_sec, \n",
    "        tempo_mean, \n",
    "        tempo_std, \n",
    "        tempo_change_count,\n",
    "        time_signature_numerator, \n",
    "        time_signature_denominator,   \n",
    "        instrument_count,\n",
    "        instrument_velocities_min, \n",
    "        instrument_velocities_max, \n",
    "        instrument_velocities_mean, \n",
    "        instrument_velocities_std, \n",
    "        instrument_pitch_10_percentile,\n",
    "        instrument_pitch_50_percentile,\n",
    "        instrument_pitch_90_percentile,\n",
    "        instrument_pitch_mean,\n",
    "        instrument_pitch_std,\n",
    "        instrument_pitch_range_by_percentiles,\n",
    "        note_durations_mean,\n",
    "        note_durations_std,\n",
    "        note_durations_range,   \n",
    "        note_density,\n",
    "        *chroma_global.tolist()\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    return {\"vector\": vec, \"names\": names} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c68e2f",
   "metadata": {},
   "source": [
    "<font size=6>Auxlilliary Data Structures</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171f7e0b",
   "metadata": {},
   "source": [
    "Auxilliary functions for creation of word sequences and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9ba93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_sequences_with_targets(tokenized_lyrics: list[str], sequence_length: int = SEQUENCE_LENGTH) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Given tokenized lyrics as a list of strings, create sequences of word indices and their corresponding target word indices.\n",
    "    Each sequence is of length `sequence_length`, and the target_sequence is a list of the next words of the sequence 1 index higher..\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    # Create sequences and targets\n",
    "    for i in range(len(tokenized_lyrics) - sequence_length):\n",
    "        seq = tokenized_lyrics[i:i + sequence_length]\n",
    "        target_sequence = tokenized_lyrics[i + 1:i + sequence_length + 1]\n",
    "        sequences.append(seq)\n",
    "        targets.append(target_sequence)\n",
    "    \n",
    "    return sequences,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0533208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SongData:\n",
    "    def __init__(self, song_data_cell: list[str] = None, midi_file: PrettyMIDI = None):\n",
    "        if len(song_data_cell) != 3:\n",
    "            raise ValueError(\"song_data_cell must have exactly three elements: [artist, title, lyrics]\")\n",
    "        self.artist = song_data_cell[0]\n",
    "        self.title = song_data_cell[1]\n",
    "        self.lyrics = song_data_cell[2]\n",
    "        self.midi_data = midi_file\n",
    "        self._midi_features: Optional[dict[str, np.ndarray]] = None\n",
    "\n",
    "    @property\n",
    "    def midi_features(self):\n",
    "        if self._midi_features is None:\n",
    "            self._midi_features = extract_midi_features(self.midi_data)\n",
    "        return self._midi_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8efdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SongDataset(data.Dataset):\n",
    "    def __init__(self, \n",
    "                songs_data: list[SongData],\n",
    "                word_embeddings: dict[str, np.ndarray],\n",
    "                artist_to_index: dict[str, int],\n",
    "                word_to_id: dict[dict, int]):\n",
    "        self.midi_features: list[np.ndarray] = list()\n",
    "        self.artists: list[str] = list()\n",
    "        self.sequence_artists: list[str] = list()\n",
    "        self.word_sequences: list[str] = list()\n",
    "        self.sequences_targets: list[str] = list()\n",
    "        self.sequence_to_midi: list[int] = list() # Maps each sequence to its corresponding MIDI feature index \n",
    "        self.sequence_to_artist: list[int] = list() # Maps each sequence to its corresponding artist embedding index\n",
    "        self.word_embeddings: dict[str, np.ndarray] = word_embeddings\n",
    "        self.artist_to_index: dict[str, np.ndarray] = artist_to_index\n",
    "        self.word_to_id: dict[str, int] = word_to_id\n",
    "        # Instead of saving each sequence's MIDI features, we save the index of the MIDI features in the midi_features list to save space.\n",
    "        for idx, song in enumerate(songs_data):\n",
    "            sequences, targets = create_word_sequences_with_targets(song.lyrics)\n",
    "            self.word_sequences.extend(sequences)\n",
    "            self.sequences_targets.extend(targets)\n",
    "            self.midi_features.append(song.midi_features['vector']) # Creates a mapping of the features to the sequences.\n",
    "            self.sequence_artists.append(song.artist)\n",
    "            self.sequence_to_midi.extend([idx] * len(sequences))\n",
    "            self.sequence_to_artist.extend([idx] * len(sequences))\n",
    "        print(f'Dataset has: {len(self.word_sequences)} sequences and {len(self.sequences_targets)} targets')\n",
    "\n",
    "    \n",
    "    def word_vec(self, tok: str) -> np.ndarray:\n",
    "        # helper to get word vector, or zeros if OOV\n",
    "        v = self.word_embeddings.get(tok)\n",
    "        if v is None:\n",
    "            sample = next(iter(self.word_embeddings.values()))\n",
    "            v = np.zeros_like(sample, dtype=np.float32)\n",
    "        return v.astype(np.float32, copy=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word_sequences)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        tokens = self.word_sequences[idx]                # list[str], len T\n",
    "        target_tokens = self.sequences_targets[idx]      # list[str], len T\n",
    "        midi = self.midi_features[self.sequence_to_midi[idx]].astype(np.float32, copy=False)\n",
    "        artist_name = self.sequence_artists[self.sequence_to_artist[idx]]\n",
    "        artist_idx = np.float32(self.artist_to_index[artist_name])\n",
    "\n",
    "        emb = np.stack([self.word_vec(tok) for tok in tokens], axis=0).astype(np.float32, copy=False)     # [T,E]\n",
    "        midi_b = np.broadcast_to(midi, (emb.shape[0], midi.shape[0])).astype(np.float32, copy=False)      # [T,M]\n",
    "        artist_b = np.full((emb.shape[0], 1), artist_idx, dtype=np.float32)                               # [T,1]\n",
    "\n",
    "        concatenated_features = np.concatenate((emb, midi_b, artist_b), axis=1).astype(np.float32, copy=False)                # [T,D]\n",
    "        target_words = np.asarray([self.word_to_id.get(target_token, self.word_to_id.get(UNK_STRING, 0)) for target_token in target_tokens],\n",
    "                   dtype=np.int64)    \n",
    "        return concatenated_features, target_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec874e9",
   "metadata": {},
   "source": [
    "<font size=6>Reading CSV files</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1959fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LYRIC_TRAIN_SET_CSV_PATH, mode='r', encoding='utf-8') as train_file:\n",
    "    reader = csv.reader(train_file)\n",
    "    lyric_train_data = list(reader)\n",
    "\n",
    "with open(LYRIC_TEST_SET_CSV_PATH, mode='r', encoding='utf-8') as test_file:\n",
    "    reader = csv.reader(test_file)\n",
    "    lyric_test_data = list(reader)\n",
    "\n",
    "if len(lyric_train_data) < 1 or len(lyric_test_data) < 1:\n",
    "    raise Exception(\"CSV files are empty or not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996afc4a",
   "metadata": {},
   "source": [
    "<font size=6>Parsing CSV files</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f5d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_csv_data(raw_csv_data: list[list[str]]) -> list[tuple[str, str, list[str]]]:\n",
    "    returned_cleaned_csv_data: list[tuple[str, str, list[str]]] = []\n",
    "    for row in raw_csv_data:\n",
    "        artist = row[0].strip()\n",
    "        title_index = 1\n",
    "        lyrics_index = 2\n",
    "        while lyrics_index < len(row):\n",
    "            title = row[title_index].strip()\n",
    "            title = title.removesuffix('-2') # Remove '-2' suffix if present, relevant in 1 case.\n",
    "            title = row[title_index].strip()\n",
    "            lyrics = row[lyrics_index].strip()\n",
    "            lyrics = lyrics.lower()\n",
    "            lyrics = re.sub(f\"[{re.escape('&')}]\", f\" {EOL_STRING} \", lyrics) # Changing ampersands to eol to indicate end of line.\n",
    "            lyrics = re.sub(f\"[{re.escape('\\'')}]\", \"\", lyrics) # Removing apostrophes.\n",
    "            lyrics = re.sub(f\"[{re.escape('-')}]\", \" \", lyrics) # Removing hyphens.\n",
    "            lyrics = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", lyrics) # Removing punctuation.\n",
    "            lyrics = lyrics.split(' ') # Tokenzing each word by space.\n",
    "            lyrics = [word.strip() for word in lyrics if word] # Removing empty strings.\n",
    "            lyrics.append(EOS_STRING) # Adding end of song token.\n",
    "            if len(title) > 0 and len(lyrics) > 0:\n",
    "                returned_cleaned_csv_data.append((artist, title, lyrics))\n",
    "            title_index += 2\n",
    "            lyrics_index += 2\n",
    "    return returned_cleaned_csv_data\n",
    "\n",
    "cleaned_lyric_train_data = clean_csv_data(lyric_train_data)\n",
    "cleaned_lyric_test_data = clean_csv_data(lyric_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ca9578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of unique words in the lyrics\n",
    "def get_word_frequencies(lyrics_data: list[tuple[str, str, list[str]]]) -> dict[str, int]:\n",
    "    words_frequency = defaultdict(int)\n",
    "    for _, _, lyrics in lyrics_data:\n",
    "        for word in lyrics:\n",
    "            words_frequency[word] += 1\n",
    "    return words_frequency    \n",
    "word_frequencies_training: dict[str, int] = get_word_frequencies(cleaned_lyric_train_data)\n",
    "word_frequencies_test: dict[str, int] = get_word_frequencies(cleaned_lyric_test_data)\n",
    "print(f\"Number of unique words in training set: {len(word_frequencies_training)}\")\n",
    "print(f\"Number of unique words in test set: {len(word_frequencies_test)}\")\n",
    "\n",
    "d_sorted_by_val = sorted(word_frequencies_training.items(), key=lambda kv: kv[1], reverse=True)\n",
    "d_sorted_by_val[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141709c5",
   "metadata": {},
   "source": [
    "<font size=6>Reading MIDI files</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80433ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_midi_files(midi_files_location: str, pickling_path: Optional[str] = None, failed_loads_path: Optional[str] = None) -> \\\n",
    "                    tuple[dict[str, dict[str, PrettyMIDI]], dict[str, set[str]]]: # artist -> title -> PrettyMIDI, failed loads[artist, song_set]\n",
    "    failed_loads = dict()\n",
    "    if failed_loads_path is not None and os.path.isfile(failed_loads_path):\n",
    "        with open(failed_loads_path, \"rb\") as f:\n",
    "            failed_loads = pickle.load(f)\n",
    "        print(f\"Loaded failed MIDI loads from pickled file {failed_loads_path}.\")\n",
    "    if pickling_path is not None and os.path.isfile(pickling_path):\n",
    "        with open(pickling_path, \"rb\") as f:\n",
    "            loaded_midi_files = pickle.load(f)\n",
    "        print(f\"Loaded MIDI files from pickled file {pickling_path}.\")\n",
    "        print(f'Loaded {sum([len(songs) for songs in loaded_midi_files.values()])} MIDI files.')\n",
    "        return loaded_midi_files, failed_loads\n",
    "    if not os.path.isdir(midi_files_location):\n",
    "        raise ValueError(f\"MIDI file path {midi_files_location} is not a valid directory.\")\n",
    "\n",
    "    # Traversing over all files and attempt to load them with pretty_midi:\n",
    "    loaded_midi_files: dict[str, dict[str, PrettyMIDI]] = defaultdict(dict) # artist -> title -> PrettyMIDI\n",
    "    failed_loads: dict[str, set[str]] = defaultdict(set)\n",
    "\n",
    "    for file in os.listdir(midi_files_location):\n",
    "        if file.endswith('.mid') or file.endswith('.midi'):\n",
    "            file_path = os.path.join(midi_files_location, file)\n",
    "            file = file.removesuffix('.mid')\n",
    "            splitted_artist_and_title = file.split('_-_')\n",
    "            artist = splitted_artist_and_title[0]\n",
    "            title = splitted_artist_and_title[1]\n",
    "            if len(splitted_artist_and_title) > 2:\n",
    "                print(f\"Warning: file {file} has more than one '_-_' separator, ignoring the rest after second \\\"_-_\\\".\")\n",
    "            artist = artist.replace('_', ' ').strip().lower()\n",
    "            title = title.replace('_', ' ').strip().lower()\n",
    "            try:\n",
    "                midi_data = PrettyMIDI(file_path)\n",
    "                loaded_midi_files[artist][title] = midi_data\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load {file}: {e}\")\n",
    "                failed_loads[artist].add(title)\n",
    "\n",
    "\n",
    "\n",
    "    if failed_loads:\n",
    "        print(\"Failed to load the following artist and lyric midi files:\")\n",
    "        for artist, lyrics in failed_loads.items():\n",
    "            print(f\"{artist} - [{', '.join(lyrics)}]\")\n",
    "\n",
    "    if pickling_path is not None:\n",
    "        with open(pickling_path, \"wb\") as f:\n",
    "            pickle.dump(loaded_midi_files, f)\n",
    "            print(f\"Pickled loaded MIDI files to {pickling_path}.\")\n",
    "    if failed_loads_path is not None:\n",
    "        with open(failed_loads_path, \"wb\") as f:\n",
    "            pickle.dump(failed_loads, f)\n",
    "            print(f\"Pickled failed MIDI loads to {failed_loads_path}.\")\n",
    "\n",
    "    print(f\"Successfully loaded {sum([len(songs) for songs in loaded_midi_files.values()])} MIDI files.\")\n",
    "    return loaded_midi_files, failed_loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a752d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_midi_files, failed_midi_loads = load_midi_files(MIDI_FILE_PATH, PICKLING_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254ffe14",
   "metadata": {},
   "source": [
    "<font size=6>Mapping CSV data to MIDI files</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43e5010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_data_to_songdata_list(csv_data: list[list[str]], \n",
    "                              failed_midi_load: dict[str, set[str]], \n",
    "                              midi_files_dict: dict[str, dict[str, PrettyMIDI]]) -> list[SongData]:\n",
    "    song_data_list: list[SongData] = list()\n",
    "    missing_midi_count = 0\n",
    "    for row in csv_data:\n",
    "        artist = row[0]\n",
    "        title = row[1]\n",
    "        if artist in failed_midi_load and title in failed_midi_load[artist]:\n",
    "            print(f\"Skipping {artist} - {title} due to previous MIDI load failure.\")\n",
    "            continue\n",
    "        if artist in midi_files_dict and title in midi_files_dict[artist]:\n",
    "            midi_file = midi_files_dict[artist][title]\n",
    "            song_data = SongData(row, midi_file)\n",
    "            song_data_list.append(song_data)\n",
    "        else:\n",
    "            missing_midi_count += 1\n",
    "            print(f\"Missing MIDI file for artist '{artist}' and title '{title}'\")\n",
    "    print(f\"Total songs with missing MIDI files: {missing_midi_count}\")\n",
    "    return song_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f061cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_midi_data: list[SongData] = csv_data_to_songdata_list(cleaned_lyric_train_data, failed_midi_loads, loaded_midi_files)\n",
    "test_midi_data: list[SongData] = csv_data_to_songdata_list(cleaned_lyric_test_data, failed_midi_loads, loaded_midi_files)\n",
    "print(f\"Total training songs with MIDI data: {len(train_midi_data)}\")\n",
    "print(f\"Total test songs with MIDI data: {len(test_midi_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8e0f1d",
   "metadata": {},
   "source": [
    "<font size=6>Handling word embeddings</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b95f984",
   "metadata": {},
   "source": [
    "Downloading pretrained word2vec, containing 300 dims, trained on news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0482d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_word2vec = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0bebb8",
   "metadata": {},
   "source": [
    "Extracting the vocabulary from the lyrics.\n",
    "Getting the data from the test set aswell since the vocbulary needs to be known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822bca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_vocabulary: set[str] = set()\n",
    "# Getting the data from the test set aswell since the vocbulary needs to be known\n",
    "for song in train_midi_data + test_midi_data:\n",
    "    for word in song.lyrics:\n",
    "        lyrics_vocabulary.add(word)\n",
    "print(f\"Total unique words in lyrics vocabulary: {len(lyrics_vocabulary)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7305abc9",
   "metadata": {},
   "source": [
    "Creating unified embedding.\n",
    "Extracting embeddings from word2vec and using random embeddings for words not found in word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d2575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_embeddings: dict[str, np.ndarray] = dict()\n",
    "existing_words_in_pretrained = 0\n",
    "not_existing_in_pretrained = 0\n",
    "added_stopwords = 0\n",
    "for word in list(lyrics_vocabulary):\n",
    "    if word in pretrained_word2vec:\n",
    "        unified_embeddings[word] = pretrained_word2vec[word]\n",
    "        existing_words_in_pretrained += 1\n",
    "    else:\n",
    "        unified_embeddings[word] = np.random.uniform(low=-1.0, high=1.0, size=(pretrained_word2vec.vector_size,)) # Random init for unknown words.  \n",
    "        not_existing_in_pretrained += 1\n",
    "    # Adding stopwords as well, since they are common and should be in the vocabulary.\n",
    "for stopword in stopwords.words('english'):\n",
    "    cleaned_stopword = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", stopword.strip().lower()) # Cleaning the stopword, since it contains punctuation.\n",
    "    if cleaned_stopword not in unified_embeddings:\n",
    "        unified_embeddings[cleaned_stopword] = np.random.uniform(low=-1.0, high=1.0, size=(pretrained_word2vec.vector_size,))\n",
    "        added_stopwords += 1\n",
    "\n",
    "print(f\"Total unique words in lyrics vocabulary: {len(lyrics_vocabulary)}\")\n",
    "print(f\"Existing words in pretrained embeddings: {existing_words_in_pretrained}\")\n",
    "print(f\"Not existing in pretrained embeddings (randomly initialized): {not_existing_in_pretrained}\")\n",
    "print(f\"Added stopwords (randomly initialized): {added_stopwords}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b23e9d",
   "metadata": {},
   "source": [
    "<font size=6>Handling artist embeddings</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f40eba",
   "metadata": {},
   "source": [
    "Using simple indexing for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e7caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_artists = [song.artist for song in train_midi_data]\n",
    "test_artists = [song.artist for song in test_midi_data]\n",
    "artist_set: set = (set(train_artists).union(set(test_artists)))\n",
    "artist_to_index: dict[str, int] = dict()\n",
    "index_to_artist: dict[int, str] = dict()\n",
    "for index, artist in enumerate(artist_set):\n",
    "    artist_to_index[artist] = index\n",
    "    index_to_artist[index] = artist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59df1ccb",
   "metadata": {},
   "source": [
    "<font size=6>Load dataset and dataloader</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84b8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = {word_in_vocab: index_of_word for index_of_word, word_in_vocab in enumerate(unified_embeddings.keys())} \n",
    "id_to_word = {index_of_word: word_in_vocab for word_in_vocab, index_of_word in word_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163de739",
   "metadata": {},
   "outputs": [],
   "source": [
    "songdata_train_dataset = SongDataset(train_midi_data, unified_embeddings, artist_to_index, word_to_id)\n",
    "songdata_test_dataset = SongDataset(train_midi_data, unified_embeddings, artist_to_index, word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee962c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, validation_set = train_test_split(songdata_train_dataset, test_size=VALIDATION_SPLIT, random_state=RANDOM_LOADER_SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667b8763",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_loader = data.DataLoader(training_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_data_loader = data.DataLoader(validation_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_data_loader = data.DataLoader(songdata_test_dataset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bfa020",
   "metadata": {},
   "source": [
    "<font size=6>Model 1: Simple concatenation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f0b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integration Method 1: Simple Concatenation - Melody features are concatenated to each word embedding\n",
    "class LyricsGenerator_Concatenation(nn.Module):\n",
    "  def __init__(self, \n",
    "               vocab_size: int, \n",
    "               input_size: int, \n",
    "               hidden_layer_dim: int, \n",
    "               size_of_midi_features: int = NUMBER_OF_EXTRACT_MIDI_FEATURES,\n",
    "               size_of_word_embeddings: int = WORD_EMBEDDING_SIZE,\n",
    "               midi_scale: float = DEFAULT_MIDI_SCALE,\n",
    "               num_layers: int = LSTM_LAYERS, \n",
    "               dropout_rate: float = DROPOUT\n",
    "               ):\n",
    "    super(LyricsGenerator_Concatenation, self).__init__()\n",
    "    self.vocab_size: int = vocab_size\n",
    "    self.num_layers: int = num_layers\n",
    "    self.midi_scale: float = midi_scale\n",
    "    self.word_embedding_size: int = size_of_word_embeddings\n",
    "    self.size_of_midi_features: int = size_of_midi_features\n",
    "    self.lstm = nn.LSTM(input_size, hidden_layer_dim, num_layers,\n",
    "                        batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_rate)\n",
    "    self.fc = nn.Linear(hidden_layer_dim, vocab_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    lstm_out, _ = self.lstm(x)\n",
    "    output_post_dropout = self.dropout(lstm_out)\n",
    "    logits = self.fc(output_post_dropout)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a569db",
   "metadata": {},
   "source": [
    "<font size=6>Model 2: Attention</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea633444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02346871",
   "metadata": {},
   "source": [
    "<font size=6>Running the models</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f210285",
   "metadata": {},
   "source": [
    "<font size=5>Running model 1: Concatenation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adb53ce",
   "metadata": {},
   "source": [
    "Add a custom loss to enforce the creation of words that look like actual lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e02754ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module, \n",
    "                train_loader: data.DataLoader, \n",
    "                val_loader: data.DataLoader, \n",
    "                test_loader: data.DataLoader,\n",
    "                word_to_id_dict: dict[str, int],\n",
    "                num_epochs: int = MAX_EPOCHS, \n",
    "                learning_rate: float = LEARNING_RATE,\n",
    "                patiance_factor: float = PATIANCE_FACTOR,\n",
    "                patiance_epochs: int = PATIANCE_EPOCHS):\n",
    "    model.to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=patiance_epochs)\n",
    "    best_model_state_dict = copy.deepcopy(model.state_dict())\n",
    "    train_losses: list[float] = list()\n",
    "    val_losses: list[float] = list()\n",
    "    test_losses: list[float] = list()\n",
    "    best_validation_loss: float = 10000.0\n",
    "    epochs_with_no_improvements: int = 0\n",
    "    writer = SummaryWriter()  # TensorBoard writer\n",
    "    vocabulary_size = model.vocab_size\n",
    "    for epoch in range(num_epochs):\n",
    "        current_time = time.time()\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        batch_num: int = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs = inputs.to(device=device, dtype=torch.float32)\n",
    "            targets = targets.to(device=device, dtype=torch.long)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(inputs)\n",
    "            loss = criterion(\n",
    "                logits[:, :-1, :].contiguous().view(-1, vocabulary_size),          # [B*(T-1), V]\n",
    "                targets[:, 1:].contiguous().view(-1)\n",
    "            )\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            batch_num += 1\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        writer.add_scalar(\"Loss/train\", epoch_loss, epoch)  # TensorBoard\n",
    "        model.eval()\n",
    "        validation_running_loss = 0.0\n",
    "        test_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in val_loader:\n",
    "                val_inputs  = val_inputs.to(device=device, dtype=torch.float32)\n",
    "                val_targets = val_targets.to(device=device, dtype=torch.long)\n",
    "\n",
    "                val_logits = model(val_inputs)  # [B, T, V]\n",
    "                val_loss = criterion(\n",
    "                    val_logits[:, :-1, :].contiguous().view(-1, vocabulary_size),\n",
    "                    val_targets[:, 1:].contiguous().view(-1)\n",
    "                )\n",
    "                validation_running_loss += val_loss.item() * val_inputs.size(0)\n",
    "            val_epoch_loss = validation_running_loss / len(val_loader.dataset)\n",
    "\n",
    "            test_running_loss = 0.0\n",
    "            for test_inputs, test_targets in test_loader:\n",
    "                test_inputs  = test_inputs.to(device=device, dtype=torch.float32)\n",
    "                test_targets = test_targets.to(device=device, dtype=torch.long)\n",
    "\n",
    "                test_logits = model(test_inputs)\n",
    "                test_loss = criterion(\n",
    "                    test_logits[:, :-1, :].contiguous().view(-1, vocabulary_size),\n",
    "                    test_targets[:, 1:].contiguous().view(-1)\n",
    "                )\n",
    "                test_running_loss += test_loss.item() * test_inputs.size(0)\n",
    "            test_epoch_loss = test_running_loss / len(test_loader.dataset)\n",
    "        scheduler.step(val_epoch_loss)\n",
    "        test_epoch_loss = test_running_loss / len(test_loader.dataset)\n",
    "        test_losses.append(test_epoch_loss)\n",
    "        if  best_validation_loss - val_epoch_loss >= patiance_factor:\n",
    "            epochs_with_no_improvements = 0\n",
    "            best_validation_loss = val_epoch_loss\n",
    "            best_model_state_dict = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            epochs_with_no_improvements += 1\n",
    "            print(f'No improvement in epoch. Patiance: {epochs_with_no_improvements}\\\\{patiance_epochs}')\n",
    "        finish_time = time.time() - current_time\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_epoch_loss:.4f}, Test Loss: {test_epoch_loss:.4f}, time: {finish_time}')\n",
    "        if epochs_with_no_improvements >= patiance_epochs:\n",
    "            print(f'Training ended prematurely due to lack of improvement.')\n",
    "            break\n",
    "    writer.close()  # Close TensorBoard writer\n",
    "    model.load_state_dict(best_model_state_dict)\n",
    "    model.eval()\n",
    "    return model, train_losses, val_losses, test_losses\n",
    "\n",
    "# After training, run in terminal to view TensorBoard:\n",
    "# !tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b319f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LyricsGenerator_Concatenation(\n",
    "    vocab_size=len(songdata_train_dataset.word_embeddings),\n",
    "    input_size=pretrained_word2vec.vector_size + NUMBER_OF_EXTRACT_MIDI_FEATURES + 1, # word embedding + melody features + artist index\n",
    "    hidden_layer_dim=256,\n",
    "    num_layers=LSTM_LAYERS,\n",
    "    dropout_rate=DROPOUT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9a6a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, training_loss, validation_loss, test_loss = train_model(model, \n",
    "            training_data_loader, \n",
    "            validation_data_loader, \n",
    "            test_data_loader,\n",
    "            word_to_id_dict=word_to_id\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27710111",
   "metadata": {},
   "source": [
    "Displaying tensorboard logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e702053",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TODO, MAKE THIS WORK LOL')\n",
    "print('TODO, MAKE THIS WORK LOL')\n",
    "print('TODO, MAKE THIS WORK LOL')\n",
    "print('TODO, MAKE THIS WORK LOL')\n",
    "# %tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd43df",
   "metadata": {},
   "source": [
    "<font size=6>Generating Lyrics</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e6c6c5",
   "metadata": {},
   "source": [
    "A function that returns the k most likely words given the input, used for coherent lyric generatin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fcf15b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_next_word(\n",
    "    model, \n",
    "    word_sequence: list[str],\n",
    "    artist_index: int,\n",
    "    melody_vec,word_to_id: dict[str, int],\n",
    "    id_to_word: dict[int, str], \n",
    "    embedding_weight: torch.Tensor,\n",
    "    device: str = \"cpu\",\n",
    "    forbidden_words: list[str] = list(),\n",
    "    strengethened_words: list[str, float] = list()):\n",
    "    model.to(device).eval()\n",
    "    if embedding_weight.device.type != device:\n",
    "        embedding_weight = embedding_weight.to(device)\n",
    "\n",
    "    # melody -> torch tensor on device\n",
    "    if not torch.is_tensor(melody_vec):\n",
    "        melody_vec = torch.as_tensor(melody_vec, dtype=torch.float32, device=device)\n",
    "    else:\n",
    "        melody_vec = melody_vec.to(device, dtype=torch.float32)\n",
    "\n",
    "    # Prepare sequence embeddings\n",
    "    unk_id = word_to_id.get(UNK_STRING, UNK_ID)\n",
    "    seq_ids = [word_to_id.get(w, unk_id) for w in word_sequence]\n",
    "    seq_embs = embedding_weight[torch.tensor(seq_ids, device=device)]  # [seq_len, emb_dim]\n",
    "\n",
    "    # Broadcast melody and artist features\n",
    "    melody_broadcast = melody_vec.expand(len(word_sequence), -1)  # [seq_len, melody_dim]\n",
    "    artist_broadcast = torch.full((len(word_sequence), 1), artist_index,\n",
    "                                  dtype=torch.float32, device=device)  # [seq_len, 1]\n",
    "\n",
    "    # Concatenate features -> [1, seq_len, input_size]\n",
    "    concatenated_features: np.ndarray = torch.cat([seq_embs, melody_broadcast, artist_broadcast], dim=1).unsqueeze(0)\n",
    "    last_step_logits = model(concatenated_features)[:, -1, :]  # [1, V]\n",
    "    last_step_logits = last_step_logits.squeeze(0)             # [V]\n",
    "\n",
    "    forb_idx = [word_to_id[w] for w in forbidden_words if w in word_to_id]\n",
    "    if forb_idx:\n",
    "        last_step_logits[torch.tensor(forb_idx, device=device, dtype=torch.long)] = float(\"-inf\")\n",
    "\n",
    "    # softmax AFTER masking\n",
    "    probs = F.softmax(last_step_logits, dim=-1)\n",
    "\n",
    "    # Mask forbidden words\n",
    "    vocab_size = probs.numel()\n",
    "    mask = torch.ones(vocab_size, device=device, dtype=probs.dtype)\n",
    "    forb_idx = [word_to_id[w] for w in forbidden_words if w in word_to_id]\n",
    "    if forb_idx:\n",
    "        last_step_logits[torch.tensor(forb_idx, device=device, dtype=torch.long)] = float(\"-inf\")\n",
    "\n",
    "    probs = F.softmax(last_step_logits, dim=-1)  # [V]\n",
    "\n",
    "    strengthened_pairs = [(w, float(p)) for (w, p) in strengethened_words if w in word_to_id]\n",
    "    if strengthened_pairs:\n",
    "        # drop any that are forbidden\n",
    "        forb_set = set(forbidden_words)\n",
    "        strengthened_pairs = [(w, max(0.0, min(p, 1.0)))\n",
    "                            for (w, p) in strengthened_pairs if w not in forb_set]\n",
    "\n",
    "        if strengthened_pairs:\n",
    "            idxs = torch.tensor([word_to_id[w] for (w, _) in strengthened_pairs],\n",
    "                                device=device, dtype=torch.long)\n",
    "            p_desired = torch.tensor([p for (_, p) in strengthened_pairs],\n",
    "                                    device=device, dtype=probs.dtype)\n",
    "\n",
    "            # If duplicates provided, aggregate their probabilities\n",
    "            uniq, inv = torch.unique(idxs, return_inverse=True)\n",
    "            p_agg = torch.zeros_like(uniq, dtype=probs.dtype).scatter_add(0, inv, p_desired)\n",
    "\n",
    "            # Zero out specified indices in the base distribution\n",
    "            base = probs.clone()\n",
    "            base[uniq] = 0.0\n",
    "            base_sum = base.sum()\n",
    "            sum_p = p_agg.sum()\n",
    "\n",
    "            if sum_p >= 1.0 - 1e-8 or base_sum <= 1e-12:\n",
    "                # Assigned probs exhaust the mass: normalize p_agg to sum 1, others 0\n",
    "                probs = torch.zeros_like(probs)\n",
    "                probs[uniq] = p_agg / (sum_p + 1e-12)\n",
    "            else:\n",
    "                # Scale the remaining (non-specified) probs to fill the leftover mass\n",
    "                remain = 1.0 - float(sum_p.item())\n",
    "                base = base * (remain / (base_sum + 1e-12))\n",
    "                probs = base\n",
    "                probs[uniq] = p_agg  # set exact targets\n",
    "        if VERBOSE:\n",
    "            vals, idxs = probs.topk(5)\n",
    "            top5 = [(id_to_word[i], float(v)) for i, v in zip(idxs.tolist(), vals.tolist())]\n",
    "            print('---------------------------')\n",
    "            print(f'current input: {word_sequence}')\n",
    "            for word_in_top_5 in top5:\n",
    "                print(word_in_top_5)\n",
    "            print('---------------------------')\n",
    "    # Sample across the full (masked) distribution â€” no top-k filtering\n",
    "    idx = torch.multinomial(probs, num_samples=1, replacement=True)\n",
    "    return id_to_word[idx.item()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2fcbb1",
   "metadata": {},
   "source": [
    "Printing the generated text and handling tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "45e527c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_generated_lyrics(generated_lyrics: list[str]):\n",
    "    capitalize = True\n",
    "    for word in generated_lyrics:\n",
    "        if word == EOL_STRING:\n",
    "            capitalize = True\n",
    "            print()\n",
    "        if word == EOS_STRING:\n",
    "            break\n",
    "        if word != EOL_STRING:\n",
    "            if capitalize:\n",
    "                capitalize = False\n",
    "                print(word.title(), end=' ')\n",
    "            else:\n",
    "                print(word, end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5239b529",
   "metadata": {},
   "source": [
    "Generating the lyrics and maintaining the lyrics generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c3392cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lyrics(\n",
    "        model_to_use: nn.Module,\n",
    "        initial_word: str,\n",
    "        melody_features: np.ndarray,\n",
    "        melody_title: str,\n",
    "        artist_to_use: str,\n",
    "        word_to_id: dict[str, int],\n",
    "        id_to_word: dict[int, str],\n",
    "        artist_to_index: dict[str, int],\n",
    "        word_embeddings: dict[str, np.ndarray],\n",
    "        max_song_length: int = MAX_SONG_LENGTH_WORDS,\n",
    "        sequence_length: int = SEQUENCE_LENGTH,\n",
    "        device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates lyrics word by word using the model, melody, and artist.\n",
    "    Picks next word randomly from top_k candidates according to their normalized probabilities.\n",
    "    Artificially increases probability of EOS_STRING after half of max_song_length.\n",
    "    Prints the generated lyrics with line breaks at <eol>.\n",
    "    Enforces some more grammatical rules.\n",
    "    Returns: generated_lyrics (list of str), artist, melody_title.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Generating song from initial word: '{initial_word}', melody: '{melody_title}', artist: '{artist_to_use}', max length: {max_song_length}\")\n",
    "    melody_vec = torch.as_tensor(melody_features['vector'], dtype=torch.float32, device=device)\n",
    "    artist_idx = artist_to_index.get(artist_to_use, -1)\n",
    "    if artist_idx == -1:\n",
    "        print(f\"Warning: Artist '{artist_to_use}' not found, using index -1.\")\n",
    "\n",
    "    embedding_weight = torch.from_numpy(\n",
    "        np.stack([word_embeddings[w].astype(np.float32) for w in word_to_id], axis=0)\n",
    "    ).to(device)\n",
    "    context: deque = deque()\n",
    "    context.extendleft([UNK_STRING for _ in range(sequence_length - 1)])\n",
    "    context.appendleft(initial_word)\n",
    "    unk_index: int = 1\n",
    "    generated_lyrics = [initial_word]\n",
    "    words_in_song: int = 0\n",
    "    current_word: str = initial_word\n",
    "    minimum_song_length = int(max_song_length / 2)\n",
    "    current_words_in_line: int = 1\n",
    "    current_word = \"\"\n",
    "    next_word = \"\"\n",
    "    words_not_to_end_lines_on: list[str] = ['the']\n",
    "    while True:\n",
    "        # Tries to enforce certain rules.\n",
    "        # Don't allow end of song before minimum amount of lines.\n",
    "        # Don't repeat the same word twice\n",
    "        # Don't allow lines that are too short.\n",
    "        # Don't end lines on words in a way that would make no sense.\n",
    "        forbidden_words = [current_word]\n",
    "        strengthened_words = list()\n",
    "        if words_in_song < int(minimum_song_length):\n",
    "            forbidden_words.append(EOS_STRING)\n",
    "        if current_word in words_not_to_end_lines_on:\n",
    "            forbidden_words.extend([EOL_STRING, EOS_STRING])\n",
    "        if current_words_in_line < MIN_LINE_LENGTH:\n",
    "            forbidden_words.append(EOL_STRING)\n",
    "        if current_words_in_line > int(MAX_LINE_LENGTH / 2):\n",
    "            probability_of_eol: float = min((current_words_in_line - int(MAX_LINE_LENGTH / 2))/ int(MAX_LINE_LENGTH/2), 1.0)\n",
    "            strengthened_words.append((EOL_STRING, probability_of_eol))\n",
    "        if words_in_song > int(MAX_SONG_LENGTH_WORDS / 2):\n",
    "            probability_of_eos: float = min((words_in_song - int(MAX_SONG_LENGTH_WORDS / 2))/ int(MAX_SONG_LENGTH_WORDS/2), 1.0)\n",
    "            strengthened_words.append((EOS_STRING, probability_of_eos))\n",
    "        next_word = predict_next_word(\n",
    "            model=model_to_use,\n",
    "            word_sequence=context,\n",
    "            artist_index=artist_idx,\n",
    "            melody_vec=melody_vec,\n",
    "            word_to_id=word_to_id,\n",
    "            id_to_word=id_to_word,\n",
    "            embedding_weight=embedding_weight,\n",
    "            forbidden_words=forbidden_words,\n",
    "            strengethened_words=strengthened_words,\n",
    "            device=device,\n",
    "        )\n",
    "        if next_word == EOS_STRING and current_word == EOL_STRING:\n",
    "            generated_lyrics[-1] = next_word # In case an end of song comes after linebreak, just end the song instead.\n",
    "        else:\n",
    "            generated_lyrics.append(next_word)\n",
    "        current_word = next_word\n",
    "        if unk_index < sequence_length:\n",
    "            context[unk_index] = next_word\n",
    "            unk_index += 1\n",
    "        else:\n",
    "            context.popleft()\n",
    "            context.append(next_word)\n",
    "        if next_word == EOS_STRING:\n",
    "            break\n",
    "        if words_in_song >= max_song_length:\n",
    "            generated_lyrics.append(EOS_STRING)\n",
    "            break\n",
    "        if next_word != EOL_STRING:\n",
    "            words_in_song += 1\n",
    "            current_words_in_line += 1\n",
    "        else:\n",
    "            current_words_in_line = 0\n",
    "    print_generated_lyrics(generated_lyrics=generated_lyrics)\n",
    "    print(f'Number of words in lyrics: {words_in_song}')\n",
    "    print(\"\\n--- End of generated lyrics ---\")\n",
    "    return generated_lyrics, artist_to_use, melody_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0acea986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating song from initial word: 'eyes', melody: 'karma chameleon', artist: 'billy joel', max length: 80\n",
      "---------------------------\n",
      "current input: deque(['do', 'every', 'you', 'eol', 'karma', 'stay', 'chameleon', 'know', 'and', 'you'])\n",
      "('eol', 0.20000000298023224)\n",
      "('i', 0.06183243542909622)\n",
      "('be', 0.060295555740594864)\n",
      "('and', 0.046929601579904556)\n",
      "('come', 0.044624026864767075)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['every', 'you', 'eol', 'karma', 'stay', 'chameleon', 'know', 'and', 'you', 'this'])\n",
      "('eol', 0.4000000059604645)\n",
      "('you', 0.09346821904182434)\n",
      "('go', 0.048077430576086044)\n",
      "('and', 0.04108539596199989)\n",
      "('your', 0.033165931701660156)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['and', 'you', 'this', 'eol', 'day', 'for', 'and', 'fear', 'and', 'the'])\n",
      "('karma', 0.15149933099746704)\n",
      "('and', 0.07596463710069656)\n",
      "('easy', 0.05934351310133934)\n",
      "('you', 0.04062054306268692)\n",
      "('i', 0.03673090785741806)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['you', 'this', 'eol', 'day', 'for', 'and', 'fear', 'and', 'the', 'karma'])\n",
      "('eol', 0.4000000059604645)\n",
      "('and', 0.09100906550884247)\n",
      "('you', 0.06473962217569351)\n",
      "('i', 0.040623150765895844)\n",
      "('to', 0.03409282863140106)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['this', 'eol', 'day', 'for', 'and', 'fear', 'and', 'the', 'karma', 'you'])\n",
      "('eol', 0.6000000238418579)\n",
      "('and', 0.045678216964006424)\n",
      "('i', 0.03247714415192604)\n",
      "('come', 0.024011678993701935)\n",
      "('me', 0.019513016566634178)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['the', 'karma', 'you', 'eol', 'we', 'to', 'you', 'youre', 'just', 'you'])\n",
      "('eol', 0.20000000298023224)\n",
      "('i', 0.07776885479688644)\n",
      "('your', 0.068886399269104)\n",
      "('to', 0.05176211893558502)\n",
      "('my', 0.044024914503097534)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['karma', 'you', 'eol', 'we', 'to', 'you', 'youre', 'just', 'you', 'find'])\n",
      "('eol', 0.4000000059604645)\n",
      "('and', 0.05725160241127014)\n",
      "('you', 0.03616097569465637)\n",
      "('heart', 0.030793072655797005)\n",
      "('i', 0.02857695333659649)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['you', 'eol', 'we', 'to', 'you', 'youre', 'just', 'you', 'find', 'old'])\n",
      "('eol', 0.6000000238418579)\n",
      "('you', 0.061477042734622955)\n",
      "('i', 0.04358121007680893)\n",
      "('day', 0.028629988431930542)\n",
      "('and', 0.028513755649328232)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['eol', 'we', 'to', 'you', 'youre', 'just', 'you', 'find', 'old', 'the'])\n",
      "('and', 0.14004284143447876)\n",
      "('but', 0.08550040423870087)\n",
      "('you', 0.048528626561164856)\n",
      "('of', 0.047356873750686646)\n",
      "('i', 0.04522056132555008)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['we', 'to', 'you', 'youre', 'just', 'you', 'find', 'old', 'the', 'and'])\n",
      "('eol', 1.0)\n",
      "('conscience', 0.0)\n",
      "('month', 0.0)\n",
      "('arm', 0.0)\n",
      "('begin', 0.0)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['old', 'the', 'and', 'eol', 'never', 'stay', 'in', 'time', 'heart', 'be'])\n",
      "('survival', 0.32006433606147766)\n",
      "('eol', 0.20000000298023224)\n",
      "('you', 0.044697102159261703)\n",
      "('and', 0.038220860064029694)\n",
      "('vision', 0.018338575959205627)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['the', 'and', 'eol', 'never', 'stay', 'in', 'time', 'heart', 'be', 'survival'])\n",
      "('eol', 0.4000000059604645)\n",
      "('and', 0.10415612906217575)\n",
      "('you', 0.08928787708282471)\n",
      "('but', 0.054995857179164886)\n",
      "('i', 0.03439807519316673)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['time', 'heart', 'be', 'survival', 'eol', 'you', 'come', 'in', 'girl', 'way'])\n",
      "('colors', 0.21499966084957123)\n",
      "('you', 0.16829118132591248)\n",
      "('eol', 0.08921817690134048)\n",
      "('i', 0.03886975720524788)\n",
      "('<eos>', 0.02500000037252903)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['heart', 'be', 'survival', 'eol', 'you', 'come', 'in', 'girl', 'way', 'you'])\n",
      "('be', 0.2649666666984558)\n",
      "('eol', 0.20000000298023224)\n",
      "('to', 0.08992762118577957)\n",
      "('<eos>', 0.05000000074505806)\n",
      "('and', 0.0191468745470047)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['be', 'survival', 'eol', 'you', 'come', 'in', 'girl', 'way', 'you', 'something'])\n",
      "('eol', 0.4000000059604645)\n",
      "('<eos>', 0.07500000298023224)\n",
      "('you', 0.05668437480926514)\n",
      "('i', 0.033290814608335495)\n",
      "('but', 0.02677326276898384)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['survival', 'eol', 'you', 'come', 'in', 'girl', 'way', 'you', 'something', 'eol'])\n",
      "('you', 0.148811936378479)\n",
      "('<eos>', 0.07500000298023224)\n",
      "('i', 0.04484192281961441)\n",
      "('thing', 0.0351969413459301)\n",
      "('never', 0.03127100691199303)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['eol', 'you', 'come', 'in', 'girl', 'way', 'you', 'something', 'eol', 'just'])\n",
      "('be', 0.13085749745368958)\n",
      "('<eos>', 0.10000000149011612)\n",
      "('to', 0.08888915926218033)\n",
      "('you', 0.07077886909246445)\n",
      "('a', 0.038641203194856644)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['you', 'come', 'in', 'girl', 'way', 'you', 'something', 'eol', 'just', 'my'])\n",
      "('<eos>', 0.125)\n",
      "('you', 0.11240851134061813)\n",
      "('and', 0.07095151394605637)\n",
      "('to', 0.06315368413925171)\n",
      "('that', 0.044428978115320206)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['come', 'in', 'girl', 'way', 'you', 'something', 'eol', 'just', 'my', 'if'])\n",
      "('<eos>', 0.15000000596046448)\n",
      "('you', 0.08077346533536911)\n",
      "('be', 0.07855170220136642)\n",
      "('i', 0.03981184959411621)\n",
      "('to', 0.03302108496427536)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['in', 'girl', 'way', 'you', 'something', 'eol', 'just', 'my', 'if', 'believe'])\n",
      "('<eos>', 0.17499999701976776)\n",
      "('you', 0.15164825320243835)\n",
      "('colors', 0.11074946075677872)\n",
      "('i', 0.04432716593146324)\n",
      "('be', 0.03132288530468941)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['girl', 'way', 'you', 'something', 'eol', 'just', 'my', 'if', 'believe', 'only'])\n",
      "('eol', 0.21689577400684357)\n",
      "('<eos>', 0.20000000298023224)\n",
      "('be', 0.06385687738656998)\n",
      "('you', 0.04919038340449333)\n",
      "('never', 0.030230581760406494)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['way', 'you', 'something', 'eol', 'just', 'my', 'if', 'believe', 'only', 'and'])\n",
      "('<eos>', 0.22499999403953552)\n",
      "('eol', 0.20000000298023224)\n",
      "('you', 0.059440843760967255)\n",
      "('me', 0.055557094514369965)\n",
      "('i', 0.05266941338777542)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['you', 'something', 'eol', 'just', 'my', 'if', 'believe', 'only', 'and', 'me'])\n",
      "('eol', 0.4000000059604645)\n",
      "('<eos>', 0.25)\n",
      "('i', 0.030112996697425842)\n",
      "('you', 0.029115933924913406)\n",
      "('to', 0.018989719450473785)\n",
      "---------------------------\n",
      "---------------------------\n",
      "current input: deque(['something', 'eol', 'just', 'my', 'if', 'believe', 'only', 'and', 'me', 'believe'])\n",
      "('eol', 0.6000000238418579)\n",
      "('<eos>', 0.2750000059604645)\n",
      "('i', 0.014189623296260834)\n",
      "('go', 0.009792914614081383)\n",
      "('you', 0.008411979302763939)\n",
      "---------------------------\n",
      "Eyes come do every you \n",
      "Karma stay chameleon know and you this \n",
      "Day for and fear and the karma you \n",
      "We to you youre just you find old the and \n",
      "Never stay in time heart be survival \n",
      "You come in girl way you something \n",
      "Just my if believe only and me believe \n",
      "Number of words in lyrics: 51\n",
      "\n",
      "--- End of generated lyrics ---\n"
     ]
    }
   ],
   "source": [
    "song_to_use = train_midi_data[63]\n",
    "\n",
    "lyrics, artist, melody = generate_lyrics(\n",
    "    model_to_use=model,\n",
    "    initial_word=\"eyes\",\n",
    "    melody_features=song_to_use.midi_features,\n",
    "    melody_title=song_to_use.title,\n",
    "    artist_to_use='billy joel',\n",
    "    word_to_id=word_to_id,\n",
    "    id_to_word=id_to_word,\n",
    "    artist_to_index=artist_to_index,\n",
    "    word_embeddings=unified_embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58b6897",
   "metadata": {},
   "source": [
    "<font size=6>Section 7, testing with the testing set</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7949fa72",
   "metadata": {},
   "source": [
    "For each melody, the output of the architecture given the melody and the initial word of the real lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "87e489d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Generating song from initial word: 'close', melody: 'eternal flame', artist: 'the bangles', max length: 95\n",
      "Close dreams cant you it we the more is the \n",
      "In life when cant that got says so by and \n",
      "To too wait so tell i \n",
      "Baby here and feeling that i see how cause say \n",
      "Going this you me is \n",
      "Call old tears you her should \n",
      "You each lonely just no \n",
      "No what are is to \n",
      "You im where go with strong the on \n",
      "Hes that a in truck im \n",
      "Can its on let dont the to \n",
      "No time the right and on \n",
      "The good oh right and \n",
      "Still no long me ride a \n",
      "Just \n",
      "Number of words in lyrics: 95\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Generating song from initial word: 'if', melody: 'honesty', artist: 'billy joel', max length: 211\n",
      "If how go on why only \n",
      "Your one the will to \n",
      "If the these can the to \n",
      "That aint in eyes aint pain you \n",
      "I me my a things play got one to \n",
      "Just strong you see now blue too to \n",
      "Upon way run you know do to you all oh \n",
      "Take day cold it a ooh we my \n",
      "Run the of its in \n",
      "Things all good in row \n",
      "Im like the before ever you to there \n",
      "Show the change was baby you \n",
      "Its the sound the time you \n",
      "Me but into time darling you and too no for \n",
      "Let know cant changed wait \n",
      "See were good love to \n",
      "I closed deep your for \n",
      "If be that in years and i \n",
      "Were and all we the that we but to with \n",
      "Maybe im the in just and \n",
      "Keep up with time and \n",
      "The a of i that know you searching and \n",
      "I that save is your \n",
      "My you want you to \n",
      "Your to me like start \n",
      "Can be how comes is your \n",
      "I me can live you \n",
      "Cant know you go like me dont be to away \n",
      "I tell aint like to you each \n",
      "Much see that wrong say each for too \n",
      "All the a of when now all their ive ones \n",
      "\n",
      "Number of words in lyrics: 211\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Generating song from initial word: 'dear', melody: 'lovefool', artist: 'cardigans', max length: 292\n",
      "Dear im fast had of \n",
      "And ill you your all my \n",
      "Now all came me with \n",
      "Dont stay bout you your who walk baby \n",
      "Its i love you of baby i to \n",
      "Ill break and baby you away \n",
      "It my turn you me \n",
      "Been for you the you \n",
      "For girl me all cry \n",
      "It you on go you and me \n",
      "Me my and me that how you i more \n",
      "To be girl i want gonna \n",
      "Girl be sad this girl this \n",
      "Know were child you to on me you cause you \n",
      "When wrong again is the baby i you oh \n",
      "Go i too you too just of with man youre \n",
      "I my you your you \n",
      "I your you every as dont you without you get \n",
      "Keep easy your no tell me but me \n",
      "Know not want be to \n",
      "Illusions in so a thing tell i know so and \n",
      "Love and you me never anymore \n",
      "Baby go her you be \n",
      "A chance your to girl and never \n",
      "You be to yeah love you \n",
      "Matter baby i turn be \n",
      "Dont hear all thing want show its \n",
      "Know its that you go girl does my \n",
      "Now my the so me my \n",
      "Every i with way stay girl know repeated you without \n",
      "Dont got for of heart on own day you \n",
      "We to your you youre \n",
      "Find it the baby your \n",
      "Dont me what listen be you \n",
      "You come got girl one you youre drive \n",
      "My if told was and me go \n",
      "Too me my you it the little love and me \n",
      "Wicked right love me my \n",
      "Should my you it of when of \n",
      "Your in girl never have never \n",
      "I caught way another or you me \n",
      "You your you if you mean alone \n",
      "Just be you \n",
      "Number of words in lyrics: 292\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Generating song from initial word: 'hiya', melody: 'barbie girl', artist: 'aqua', max length: 390\n",
      "Hiya be i feel since \n",
      "Loves love true ooh theres can me \n",
      "You scared when say this could me do and think \n",
      "I be you me baby \n",
      "Been what day take be easy i what know i \n",
      "Were since my me when do go \n",
      "Than to go that you say and dont somebody \n",
      "What the we you my \n",
      "Baby can me him like by me gone ive me \n",
      "Always feel come chance may i \n",
      "People didnt to you or oh one i out been \n",
      "Down world rock cause know sometimes \n",
      "Gonna be me and me youll is \n",
      "Waits about im thats already making \n",
      "Else tell you the day want leave you way can \n",
      "Me so long maybe it me got this i it \n",
      "Baby you and feel thats to it can you and \n",
      "You on know then day and can \n",
      "Of i a you what \n",
      "Another to i the time \n",
      "You never me youve ooh i just high own just \n",
      "Sometimes be see you im you who all go and \n",
      "Can so just no it can baby what am only \n",
      "Im al a of on go and im is you \n",
      "Im yeah you already maybe \n",
      "Girl youre to a time true way now feel do \n",
      "Baby me baby i what say me say you see \n",
      "Now have be come time you \n",
      "That be a day you me \n",
      "The you years do be and me feel but \n",
      "Its is for all to \n",
      "Wait year take strange the oh for \n",
      "He day only be how day only same \n",
      "Its go im you do when fades the and dont \n",
      "Let have heartbreak we come you \n",
      "This man you i down when time if say gone \n",
      "Day have long one when gone and i never \n",
      "You say youll say a b to \n",
      "You my your a that i \n",
      "You help little away the right you could back down \n",
      "As get melody you me my \n",
      "Can to funny yes well and cause not say what \n",
      "Want what do be say i know you be you \n",
      "I it out this one good you \n",
      "Love i what lover is \n",
      "For way say just oh come dawn and i a \n",
      "As you to you away you can \n",
      "I never say whats you when this \n",
      "Before as all you i do little makes to \n",
      "Never really a of all can \n",
      "Number of words in lyrics: 390\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Generating song from initial word: 'all', melody: 'all the small things', artist: 'blink 182', max length: 176\n",
      "All a town old now a shes \n",
      "Girlfriend make hot with and time \n",
      "Me im to man would you my \n",
      "You find for morning a \n",
      "A cat i up are \n",
      "The you not feelin they im all \n",
      "Know all out like girlfriend show dont i hair because \n",
      "You want guy theres to up i \n",
      "Said gonna up i train because on leave \n",
      "Laughs down the that out the from blame when the \n",
      "In mirror up know on waiting everybodys for side the \n",
      "I like my that on \n",
      "Will seem my or on \n",
      "I be will the time \n",
      "Prefer all cause said me from sure now the when \n",
      "That once need right it the dream \n",
      "Gotta up moving in bulge \n",
      "Laughs on the sign i away tell and \n",
      "Shes thats to it old anything please know until need \n",
      "Dont to all my no i it up out are \n",
      "Everybodys it on and like on time you \n",
      "From get dont me to \n",
      "The of to a oblivion i the you \n",
      "Its back what is like \n",
      "Run and dont gonna \n",
      "Number of words in lyrics: 176\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "for test_song in test_midi_data:\n",
    "    print('--------------------------------')\n",
    "    test_song: SongData\n",
    "    lyrics, artist, melody = generate_lyrics(\n",
    "        model_to_use=model,\n",
    "        initial_word=test_song.lyrics[0],\n",
    "        melody_features=test_song.midi_features,\n",
    "        melody_title=test_song.title,\n",
    "        artist_to_use=test_song.artist,\n",
    "        word_to_id=word_to_id,\n",
    "        id_to_word=id_to_word,\n",
    "        artist_to_index=artist_to_index,\n",
    "        word_embeddings=unified_embeddings,\n",
    "        max_song_length=len([word for word in test_song.lyrics if word != EOL_STRING])\n",
    "    )\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92433b27",
   "metadata": {},
   "source": [
    "For each melody, the output of the architecture given the melody and different starting words. The same word should be used for all melodies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cd0dea71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Initial Word Selected: love-------------------\n",
      "--------------------------------\n",
      "Generating song from initial word: 'love', melody: 'eternal flame', artist: 'the bangles', max length: 95\n",
      "Love and why the when going \n",
      "Not ill just to we tonight \n",
      "You to goodbye wanna its in kiss im know for \n",
      "Of is man its no on why my is just \n",
      "They her so cant dont double a \n",
      "Thing i nothing where look my \n",
      "Ill cause do come so be \n",
      "Why is gone the on \n",
      "Thats say the is whom dont the to \n",
      "Call listen of and all aint one when not to \n",
      "Would go baby you care is that its for \n",
      "Tried up striving the a her \n",
      "Still listen in middle day just \n",
      "Says \n",
      "Number of words in lyrics: 95\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Generating song from initial word: 'love', melody: 'honesty', artist: 'billy joel', max length: 211\n",
      "Love take i a ooh \n",
      "Me way long alone like \n",
      "Got to lover out if never mean do just care \n",
      "Ooh all i and in \n",
      "A of people dont thought laugh you lonely \n",
      "Away the people have trees \n",
      "Of wind cold with the of \n",
      "The of now of you and cant find just this \n",
      "Of just left in through up a of i that \n",
      "The one old heart a or stand \n",
      "We that i this girl more \n",
      "That the this day aint and just \n",
      "Ill to you your you wouldve i dont \n",
      "My that cant be was again that its \n",
      "That know this the is in \n",
      "A your how i me very and \n",
      "What taken to that in dark i you your \n",
      "I words i let see world \n",
      "They i see name with baby what youre for be \n",
      "I what a you if could love take your when \n",
      "I give time the be her \n",
      "For a who cant leave it ive that down \n",
      "Prison dont to away truth a \n",
      "Then where just lose had im aint down me youre \n",
      "Now thinking oh no your \n",
      "Ill no and dont go freedom take think but say \n",
      "Know from i so know got for \n",
      "To somebody a girl me \n",
      "In my of in you i \n",
      "Number of words in lyrics: 211\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Generating song from initial word: 'love', melody: 'lovefool', artist: 'cardigans', max length: 292\n",
      "Love and dream i but to now \n",
      "Dont to you do same gonna you \n",
      "You the to i lonely way youve someone i you \n",
      "I to me when gonna for of heart on \n",
      "You she no when my \n",
      "Baby was want i you me but you me you \n",
      "You just you have how be \n",
      "You me you down and my \n",
      "Youre only one look to us \n",
      "A and dont the you \n",
      "Just easy you so come \n",
      "Karma be you now stars i you \n",
      "Love wont im here every you \n",
      "Dont about really you your to \n",
      "Illusions thing only is be you oh girl its \n",
      "Me know to you baby \n",
      "You want be for stars you got be you your \n",
      "Woo it girl not be but if were \n",
      "My is you me just for \n",
      "And the comes the all a \n",
      "Stay no you to me other alright get way give \n",
      "Your fantasy tell i you \n",
      "The that you know you be a \n",
      "I what you have love lose for \n",
      "You lose a to dont when last \n",
      "Let see long only no \n",
      "Gonna i want right you \n",
      "We a of cant to just \n",
      "My you a girl your \n",
      "Know never be but you \n",
      "Take the to it you i to \n",
      "Wont you it somebody me \n",
      "Told something you your so \n",
      "Cant crazy be just you \n",
      "Girl you it gone i when repeated \n",
      "I someone be what mean you \n",
      "Cant you say how mean can someone but what i \n",
      "Cant be just be lonely of \n",
      "To with her all my \n",
      "Want it go and i you and \n",
      "How want understand i be so \n",
      "Since you i know could want go how do please \n",
      "Know i do mean want mean have for \n",
      "Say were you to you \n",
      "Number of words in lyrics: 292\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Generating song from initial word: 'love', melody: 'barbie girl', artist: 'aqua', max length: 390\n",
      "Love hey im do i im \n",
      "In at and dont feel there well they see wont \n",
      "Its so leave can in \n",
      "Youve to my a of \n",
      "Boy stand you do be \n",
      "I that you stop you into \n",
      "You the maybe when a \n",
      "You youre best in guest youve go must we \n",
      "Wonder when since say right you go come that me \n",
      "Not oh let know that what do maybe what \n",
      "Again baby oh gonna you when \n",
      "They make been a one \n",
      "I a through who you want touch a \n",
      "When your i will me oh \n",
      "Im for when have ever \n",
      "That me you me heaven now they i for little \n",
      "Youll you to our at \n",
      "My i talk youre and i will all \n",
      "I have waiting a where whats you true this just \n",
      "Only right be what drive girl \n",
      "Through you without you see day \n",
      "Who if mean must will me like lonely gone \n",
      "Im a man no shine \n",
      "May in five when you \n",
      "Oo i cant nobody much today its too i im \n",
      "They times got for i im \n",
      "And you ive to the free \n",
      "Your out way got be \n",
      "On de own of and \n",
      "You be something i you what \n",
      "I to what you could you \n",
      "What if you let to them oh \n",
      "Know mean do made i no \n",
      "Wont see day i theres you like eat you been \n",
      "All before do youre in too i your \n",
      "Comin myself a in i time and will on the \n",
      "Like me go away me ooh me baby what i \n",
      "I get you girl have can \n",
      "A b one can oh love what come me aint \n",
      "Its to know just have do \n",
      "Number of words in lyrics: 280\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Generating song from initial word: 'love', melody: 'all the small things', artist: 'blink 182', max length: 176\n",
      "Love shes she cant and \n",
      "Right the to up bed my \n",
      "Enough i her with make \n",
      "Of time to you my \n",
      "Thats make you when would \n",
      "Stay on baby i a \n",
      "My is to better to \n",
      "The be to fine the from \n",
      "Up right on waiting a from and me the then \n",
      "Am out of up and \n",
      "To up a and a little for \n",
      "Me the that i to \n",
      "To better the to i look \n",
      "How will and be it from something see i want \n",
      "You about have make i when love \n",
      "Dont to your to the so \n",
      "I dont good world i \n",
      "The girl gotta down up when gotta up \n",
      "Know time to that to along she my \n",
      "Just on mind food him \n",
      "I to me think i of time find her \n",
      "It shes to place i wait much i jealous your \n",
      "Then that cant really sitting goin i everybodys so like \n",
      "Gotta that all pride quite time as dont up the \n",
      "Whats i you my too yeah give vacation because youre \n",
      "For dumb i stay \n",
      "Number of words in lyrics: 176\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n",
      "-------------Initial Word Selected: baby-------------------\n",
      "--------------------------------\n",
      "Generating song from initial word: 'baby', melody: 'eternal flame', artist: 'the bangles', max length: 95\n",
      "Baby not im to he always making hope take god \n",
      "That was for is when need know if she this \n",
      "Just of and the is of on but gone its \n",
      "You to your so come cause is \n",
      "Baby me for i this just dont up the cup \n",
      "All is what my thats \n",
      "Always lonely youre where a \n",
      "You what in coming is and ive when \n",
      "You a i for one as change \n",
      "Its him a just his \n",
      "Going its in day dont wear \n",
      "Haunted memories and so the but and nothing do gotta \n",
      "Dont not out \n",
      "Number of words in lyrics: 95\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Generating song from initial word: 'baby', melody: 'honesty', artist: 'billy joel', max length: 211\n",
      "Baby and i for i and then \n",
      "Not show the that stop a of row \n",
      "Caught your of day in is \n",
      "Im know were way been \n",
      "These a end as and \n",
      "Your show cold so i before reaching home love \n",
      "Time find so you my to you \n",
      "Been from heart dont got these well all got about \n",
      "Baby goin and there to away \n",
      "They the in we where can you your \n",
      "I know cant get in when keep life when not \n",
      "Got place in world makes go \n",
      "Youre man of dont aint much no got \n",
      "Maybe stole way still your oh look \n",
      "The i still me see \n",
      "My its of and know i be \n",
      "To you out just of \n",
      "See his one in there dont this in father where \n",
      "Ill take lot a bitch late get that lost i \n",
      "Got papers every will like \n",
      "Your aint but have been but then so \n",
      "You so that girl is just \n",
      "Not to on in sleep we through \n",
      "Gave and that im too in eyes ill \n",
      "A you that you me \n",
      "Is just heart pain where face the things by \n",
      "Things were the down these \n",
      "Make to you tell got me long go come \n",
      "In we together the of \n",
      "I show youre you out \n",
      "My \n",
      "Number of words in lyrics: 211\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Generating song from initial word: 'baby', melody: 'lovefool', artist: 'cardigans', max length: 292\n",
      "Baby i die what said you never but get this \n",
      "You so for they be \n",
      "May for girl just me i a long me \n",
      "Want be you new friends you \n",
      "We me you i you the will you before you \n",
      "You i you me to \n",
      "Dont me save me yeah out before baby \n",
      "You be that a love \n",
      "Gonna your on now as stay oh lets so \n",
      "Been you my by dont all and cant be myself \n",
      "Day what you my good preicous \n",
      "Wonder as like the in \n",
      "Keep life to in one love youre to over and \n",
      "You it and you so you right \n",
      "Never know i to me \n",
      "You me my you yeah just i to \n",
      "You to who goodbye time to that what mean be \n",
      "I be you your when you \n",
      "Me be a more time \n",
      "No your you it me \n",
      "And you me waiting turn \n",
      "Im to me do last \n",
      "A time know share a \n",
      "My and day that of is dreams why do feeling \n",
      "Say you to you be so \n",
      "I care so to love listen \n",
      "Know well should know my \n",
      "Want know i all you \n",
      "All and i to you \n",
      "You girl me to you with \n",
      "Much to you your me \n",
      "Baby only what be time \n",
      "Let want spend you your \n",
      "Said love i him you \n",
      "Lover stay you to you what out get a \n",
      "Me you me now love \n",
      "Dont how that you know been at \n",
      "Its to like yeah there your \n",
      "You me smart tell huh you know i my you \n",
      "Just go be turn to \n",
      "And you me trust yeah \n",
      "Dont come crazy baby i you \n",
      "An a turn i for now as me \n",
      "You alright can a just to in girl tell say \n",
      "\n",
      "Number of words in lyrics: 292\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Generating song from initial word: 'baby', melody: 'barbie girl', artist: 'aqua', max length: 390\n",
      "Baby you sometimes now get i will \n",
      "Brighter i that me see day they \n",
      "I believe you do go makes \n",
      "Love all i so how you what just \n",
      "What mean say go to for more what say girl \n",
      "When can a you a times this \n",
      "I love see as before cant run the blame and \n",
      "Run should you way makes of \n",
      "Knew ever some he gone through the was song but \n",
      "It be didnt the me the guest \n",
      "When dont run me thats do its say you sing \n",
      "Want be go i be you me \n",
      "I my you me you me \n",
      "How really you it so baby you \n",
      "So dont so me just like can \n",
      "I you it you breathe can \n",
      "I know can know this b \n",
      "We know you someone at down and i want you \n",
      "Show got gone i be you a of \n",
      "Can loneliness so the away youre \n",
      "You be of i so just into end friends \n",
      "Now that will be i heart life girls make just \n",
      "The is on night so \n",
      "Always that only more want \n",
      "The this when not me \n",
      "In way should day can a once every a \n",
      "You i do hear i go cant what i that \n",
      "You be out town the just baby this \n",
      "When feel that lonely dont myself me its you this \n",
      "My song me every love out true only me free \n",
      "When can see oh day you i and me boy \n",
      "Are came touching world i to you me with again \n",
      "You have you be gone this against \n",
      "You my you to my now more fall your \n",
      "Run i to you know you to \n",
      "Will hold to me run we \n",
      "Something been world know baby \n",
      "Number of words in lyrics: 285\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Generating song from initial word: 'baby', melody: 'all the small things', artist: 'blink 182', max length: 176\n",
      "Baby last find like get you shes she the all \n",
      "I make wait she shes up ill one \n",
      "Feel i you easy leave on door shes not jealous \n",
      "Said gone just what think me when \n",
      "Dont feel they giving pride how move down shes i \n",
      "My and on at heart would know but cant watch \n",
      "Am the from for you and got \n",
      "From midnight a of from time my \n",
      "Late sun on her on girl \n",
      "Dont get guy would am im live say you a \n",
      "If from shes all when old or for \n",
      "Im fight a with pencil everybodys to \n",
      "I the im for good \n",
      "Im need get back your \n",
      "Run need know what she you to \n",
      "My turn run cause yeah the boy i \n",
      "Yeah feel you in and i to \n",
      "We you my like baby \n",
      "A hand a is sitting and \n",
      "Me its in to see come takes out a \n",
      "Hope gotta you still shes her it your \n",
      "Now did me i need \n",
      "I where hang your but she all guy you i \n",
      "Think can \n",
      "Number of words in lyrics: 176\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n",
      "-------------Initial Word Selected: time-------------------\n",
      "--------------------------------\n",
      "Generating song from initial word: 'time', melody: 'eternal flame', artist: 'the bangles', max length: 95\n",
      "Time i her we come \n",
      "They was this cause work by that theres at \n",
      "Cant no for when time you where i in is \n",
      "High burning an for when ill no good \n",
      "The for in world they away but know can the \n",
      "Thats my the for of no thinking be has \n",
      "On at city why sun \n",
      "About have at youre right in \n",
      "Im in we where got of too my \n",
      "Us what want dream the is \n",
      "Im only for miles heaven life come \n",
      "Where and at now alone come \n",
      "As one through my shes \n",
      "Dont see \n",
      "Number of words in lyrics: 95\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Generating song from initial word: 'time', melody: 'honesty', artist: 'billy joel', max length: 211\n",
      "Time theres lets and for a how what cant through \n",
      "Just need without as time take \n",
      "Not what to you it you the to new \n",
      "Think morning a around howve bet \n",
      "I had such im girl in \n",
      "Dont you seen there eyes things i to \n",
      "Know see so my i what mean if is sweet \n",
      "Just no the i see eyes ive into but i \n",
      "Mean know mean be pain her \n",
      "Know now the of just the i here know i \n",
      "You see its new dont things asking has your girl \n",
      "You your that i escape these the no true you \n",
      "Want know i a was father \n",
      "As always its is then i mean things that have \n",
      "Word know gotta the differently be your \n",
      "Want know you be same there the but see when \n",
      "Your a out cant so as matter \n",
      "That be you then you through to \n",
      "I my to i come im \n",
      "In and i you the to \n",
      "I to a to a i \n",
      "Ever tell have could so \n",
      "Must got heart long will \n",
      "Baby the that between world girl oh \n",
      "Number of words in lyrics: 182\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Generating song from initial word: 'time', melody: 'lovefool', artist: 'cardigans', max length: 292\n",
      "Time be how what youre \n",
      "You and little ive one \n",
      "You and when be you \n",
      "You be first you how as you me \n",
      "Feel ever you why so i that say show you \n",
      "Just little you how colors i is be \n",
      "Know i it be you \n",
      "So never your and to your \n",
      "I love when hear you about words oh only we \n",
      "Ooh no were of yeah may for closer free \n",
      "Me the i you for \n",
      "I you your for two oh some feel be so \n",
      "Be i be of so \n",
      "Gonna me on you me like \n",
      "String in heart until said \n",
      "Tell the thats to and if could wrong something so \n",
      "You me you so all i down that yeah cut \n",
      "Your are way you there \n",
      "A as a up as gold i dont what gonna \n",
      "That to a right i be \n",
      "Never be fall your my \n",
      "Ill believe it be and \n",
      "Said i understand good girl you \n",
      "Never know be you that do be \n",
      "Alone ever be you me baby you \n",
      "Love you me you my \n",
      "I mean something give youre \n",
      "Im it love show you \n",
      "A that how had give \n",
      "You a that every ill me \n",
      "The you easy me love but day i got for \n",
      "I the you that do and know all what mean \n",
      "Is youve be you to \n",
      "You me i knew but anything but you someone with \n",
      "I for you and in but yeah i you \n",
      "Only go you understand are \n",
      "Give to me the with \n",
      "Youre sea when be come you im \n",
      "You your you tell my like baby \n",
      "I know i you to a man love \n",
      "Let be wrong love me but come \n",
      "A to a place yeah \n",
      "You get now you never you \n",
      "Number of words in lyrics: 292\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Generating song from initial word: 'time', melody: 'barbie girl', artist: 'aqua', max length: 390\n",
      "Time you another will since theres swear and \n",
      "Freedom i you when understand can tell when how do \n",
      "Up i want say do want \n",
      "Me i he cant to me away when you me \n",
      "Something you say i say been \n",
      "Wont feel love still a and im inside through \n",
      "Of are surroundin chance will you bad me \n",
      "I me you some me guy got up since i \n",
      "I believe you what do be \n",
      "Dont it for of girl all i \n",
      "Be one a girl you will to \n",
      "My i time youve what do what mean be away \n",
      "Around dont some man oh wont \n",
      "But be will i so \n",
      "What have do be today of \n",
      "Just my see you moon go only can me \n",
      "What could feels in eyes you driving \n",
      "You to your there that really \n",
      "You fantasy you the long \n",
      "You me to me a \n",
      "A love sit a cause a shivers the to the \n",
      "Let time maybe will see so say i \n",
      "Can tell me stop gone \n",
      "Its what time know gone three thats mean \n",
      "I be they some breathe me had \n",
      "Me how never love night id \n",
      "You oo got for think love \n",
      "Say be too say can \n",
      "What one life the i when after to \n",
      "Know really to some be \n",
      "My is baby yeah me make be and \n",
      "The your and the love me to \n",
      "Only no when find so i you to you so \n",
      "When girls said had do you not cause i this \n",
      "What im you up im the go when got \n",
      "And tears they i it my \n",
      "You me i go for is \n",
      "Waits say you can have you oh i \n",
      "Cant make its friends i to cant you \n",
      "That have go and true you its in \n",
      "Now we some on just baby \n",
      "Never have want say i \n",
      "Always mean you me say gone can go and must \n",
      "This my girl im some i feel find when \n",
      "Loves i you me girl when gone go matter way \n",
      "Be the than sure waits girl i you me you \n",
      "Yeah you something and hard you already oh what i \n",
      "Always on you at three as look when \n",
      "You to me think to me im \n",
      "You know be of can this so aint and \n",
      "Was through thats and aint and time when \n",
      "Think you me nice oh \n",
      "Number of words in lyrics: 390\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Generating song from initial word: 'time', melody: 'all the small things', artist: 'blink 182', max length: 176\n",
      "Time a say give prefer i right im \n",
      "Sitting youre up time dont \n",
      "Because watch try for of \n",
      "Time alone me you up to the i stay get \n",
      "Havent say feel whats up call jealous i \n",
      "Is my jealous i too \n",
      "Whats the was up to when \n",
      "A that to down gotta \n",
      "In old wait you know youre \n",
      "Out three like love when you around and at of \n",
      "I you it so keep fuck now a to \n",
      "Do try want last you when you i im without \n",
      "The like through to room on \n",
      "My up from dumb away i there baby more \n",
      "Think not one through somebody feel \n",
      "To listen right laughs me \n",
      "The turned just the there im i \n",
      "That wait you to me \n",
      "At air window all here \n",
      "Im little didnt gonna away \n",
      "Do fight big shes jokes \n",
      "You her would me to but im us know its \n",
      "Moving my cut on when loved to \n",
      "The no for i to \n",
      "The has on fight i swallow \n",
      "The last just that with time they \n",
      "But dont \n",
      "Number of words in lyrics: 176\n",
      "\n",
      "--- End of generated lyrics ---\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "starting_words: list[str] = ['love', 'baby', 'time']\n",
    "\n",
    "for word in starting_words:\n",
    "    print(f'-------------Initial Word Selected: {word}-------------------')\n",
    "    for test_song in test_midi_data:\n",
    "        print('--------------------------------')\n",
    "        test_song: SongData\n",
    "        lyrics, artist, melody = generate_lyrics(\n",
    "            model_to_use=model,\n",
    "            initial_word=word,\n",
    "            melody_features=test_song.midi_features,\n",
    "            melody_title=test_song.title,\n",
    "            artist_to_use=test_song.artist,\n",
    "            word_to_id=word_to_id,\n",
    "            id_to_word=id_to_word,\n",
    "            artist_to_index=artist_to_index,\n",
    "            word_embeddings=unified_embeddings,\n",
    "            max_song_length=len([word for word in test_song.lyrics if word != EOL_STRING])\n",
    "        )\n",
    "        print('--------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
